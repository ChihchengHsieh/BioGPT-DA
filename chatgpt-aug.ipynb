{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from transformers import pipeline, set_seed\n",
    "from transformers import BioGptTokenizer, BioGptForCausalLM\n",
    "from aug.gpt import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "MIMIC_EYE_PATH = \"F:\\\\mimic-eye\"\n",
    "\n",
    "REFLACX_LESION_LABEL_COLS = [\n",
    "    # \"Fibrosis\",\n",
    "    # \"Quality issue\",\n",
    "    # \"Wide mediastinum\",\n",
    "    # \"Fracture\",\n",
    "    # \"Airway wall thickening\",\n",
    "\n",
    "    ######################\n",
    "    # \"Hiatal hernia\",\n",
    "    # \"Acute fracture\",\n",
    "    # \"Interstitial lung disease\",\n",
    "    # \"Enlarged hilum\",\n",
    "    # \"Abnormal mediastinal contour\",\n",
    "    # \"High lung volume / emphysema\",\n",
    "    # \"Pneumothorax\",\n",
    "    # \"Lung nodule or mass\",\n",
    "    # \"Groundglass opacity\",\n",
    "    ######################\n",
    "    \"Pulmonary edema\",\n",
    "    \"Enlarged cardiac silhouette\",\n",
    "    \"Consolidation\",\n",
    "    \"Atelectasis\",\n",
    "    \"Pleural abnormality\",\n",
    "    # \"Support devices\",\n",
    "]\n",
    "\n",
    "\n",
    "CHEXPERT_LABEL_COLS = [\n",
    "    \"Atelectasis_chexpert\",\n",
    "    \"Cardiomegaly_chexpert\",\n",
    "    \"Consolidation_chexpert\",\n",
    "    \"Edema_chexpert\",\n",
    "    \"Enlarged Cardiomediastinum_chexpert\",\n",
    "    \"Fracture_chexpert\",\n",
    "    \"Lung Lesion_chexpert\",\n",
    "    \"Lung Opacity_chexpert\",\n",
    "    \"No Finding_chexpert\",\n",
    "    \"Pleural Effusion_chexpert\",\n",
    "    \"Pleural Other_chexpert\",\n",
    "    \"Pneumonia_chexpert\",\n",
    "    \"Pneumothorax_chexpert\",\n",
    "    \"Support Devices_chexpert\", \n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from secret import *\n",
    "openai.api_key = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_aug =  [\n",
    "            \"temperature_c\",\n",
    "            \"heartrate\",\n",
    "            \"resprate\",\n",
    "            \"o2sat\",\n",
    "            \"sbp\",\n",
    "            \"dbp\",\n",
    "        ]\n",
    "\n",
    "feature_to_name_map = {\n",
    "    \"temperature_c\": \"body temperature in degrees Celsius\",\n",
    "    \"heartrate\": \"heart rate in beats per minute\",\n",
    "    \"resprate\": \"respiratory rate in breaths per minute\",\n",
    "    \"o2sat\": \"peripheral oxygen saturation (%)\",\n",
    "    \"sbp\": \"systolic blood pressure (mmHg)\",\n",
    "    \"dbp\":\"diastolic blood pressure (mmHg)\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_word_value(outputs, min_max_v) :\n",
    "    for o in outputs: \n",
    "        next_word = o.split(\" \")[0]\n",
    "        # next_num_str =  \"\".join(filter(str.isnumeric, next_word))\n",
    "        next_num_str = re.sub(\"[^0-9.]\", \"\", next_word).replace(\"..\", \".\")\n",
    "        # if next_num_str.count(\".\") <= 1 and len(next_num_str.replace(\".\", \"\")) > 0:\n",
    "        try:\n",
    "            v = float(next_num_str)\n",
    "        except:\n",
    "            continue\n",
    "            # check if v in the range\n",
    "        min_v, max_v = min_max_v\n",
    "        if v > min_v and v < max_v:\n",
    "            return True, v\n",
    "    return False, next_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tenacity import (\n",
    "    retry,\n",
    "    stop_after_attempt,\n",
    "    wait_random_exponential,\n",
    "    retry_if_exception_type\n",
    ")  # for exponential backoff\n",
    "\n",
    "@retry(\n",
    "    retry=retry_if_exception_type((openai.error.APIError, openai.error.APIConnectionError, openai.error.RateLimitError, openai.error.ServiceUnavailableError, openai.error.Timeout)), \n",
    "    wait=wait_random_exponential(multiplier=1, max=60), \n",
    "    stop=stop_after_attempt(10)\n",
    ")\n",
    "def chat_completion_with_backoff(**kwargs):\n",
    "    return openai.ChatCompletion.create(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Couldn't find value for [5] prompt: EXAMINATION:  CHEST PA AND LAT  INDICATION:  History: M with chest pain  TECHNIQUE:  Chest PA and lateral  COMPARISON:    FINDINGS:   The patient is status post median sternotomy and CABG.  Cardiac mediastinal and hilar contours are unchanged with the heart size within normal limits. Minimal atherosclerotic calcifications are noted at the aortic knob. Pulmonary vasculature is normal. Calcified granuloma is seen within the right apex.  Lungs are clear. Pulmonary vasculature is normal. No pleural effusion or pneumothorax is present. Minimal degenerative changes are seen within the thoracic spine.  IMPRESSION:   No acute cardiopulmonary abnormality. LESIONS: Atelectasi. AGE: 73. GENDER: Male. body temperature in degrees Celsius:, the next word is There\n",
    "# failed in sbp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What can be the next word for the following context (please only return one numerical word): EXAMINATION:  CHEST PA AND LAT  INDICATION:  History: M with chest pain  TECHNIQUE:  Chest PA and lateral  COMPARISON:    FINDINGS:   The patient is status post median sternotomy and CABG.  Cardiac mediastinal and hilar contours are unchanged with the heart size within normal limits. Minimal atherosclerotic calcifications are noted at the aortic knob. Pulmonary vasculature is normal. Calcified granuloma is seen within the right apex.  Lungs are clear. Pulmonary vasculature is normal. No pleural effusion or pneumothorax is present. Minimal degenerative changes are seen within the thoracic spine.  IMPRESSION:   No acute cardiopulmonary abnormality. LESIONS: Atelectasi. AGE: 73. GENDER: Male. body temperature in degrees Celsius:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['temperature_c', 'heartrate', 'resprate', 'o2sat', 'sbp', 'dbp']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_to_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NTU, or National Taiwan University, is located in Taipei, Taiwan. Specifically, it is in the Da’an District of Taipei City.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# res = chat_completion_with_backoff(\n",
    "#                 model=\"gpt-4\",\n",
    "#                 messages=[\n",
    "#                     {\"role\": \"system\", \"content\": \"You are a helpful assistant providing information and answering questions related to Taiwan.\"},\n",
    "#                     {\"role\": \"system\", \"content\": \"Where is NTU?\"},\n",
    "#                 ],\n",
    "#                 temperature=0.1,\n",
    "#             )\n",
    "# res['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolving temperature_c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/799 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 799/799 [1:01:07<00:00,  4.59s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolving heartrate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 799/799 [58:47<00:00,  4.41s/it]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolving resprate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 799/799 [18:13<00:00,  1.37s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolving o2sat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 799/799 [31:37<00:00,  2.37s/it]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolving sbp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 799/799 [47:46<00:00,  3.59s/it]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolving dbp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 799/799 [46:38<00:00,  3.50s/it]    \n"
     ]
    }
   ],
   "source": [
    "for rf in [\n",
    "    True,\n",
    "    # False,\n",
    "]:\n",
    "    report_format = rf\n",
    "    df = pd.read_csv('./spreadsheets/reflacx_clinical.csv')\n",
    "    df['temperature_c'] = df['temperature'].apply(lambda f :(f-32) * 5/9 )\n",
    "    aug_feature_range = {f: (df[f].min(), df[f].max()) for f in features_to_aug}\n",
    "\n",
    "    for f in features_to_aug:\n",
    "        df[f\"aug_{f}\"] = None\n",
    "\n",
    "    for f in features_to_aug:\n",
    "        print(f\"Resolving {f}\")\n",
    "        # aug the instance one by one\n",
    "        for idx, data in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "            prompt = get_prompt(\n",
    "                MIMIC_EYE_PATH,\n",
    "                data,\n",
    "                REFLACX_LESION_LABEL_COLS,\n",
    "                feature_to_name_map,\n",
    "                f,\n",
    "                report_format=report_format,\n",
    "            )\n",
    "            res = chat_completion_with_backoff(\n",
    "                # model=\"gpt-3.5-turbo\",\n",
    "                model=\"gpt-4\",\n",
    "                messages=[\n",
    "                    # {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                    {\"role\": \"system\", \"content\": \"You are a medical expert predicting the possible value of clinical features.\"},\n",
    "                    {\"role\": \"user\", \"content\": f\"What can be the next word for the following context (please only return one numerical word):\\n\\n {prompt}\"},\n",
    "                ],\n",
    "                temperature=0.2,\n",
    "                n=50\n",
    "            )\n",
    "\n",
    "            res = [c['message']['content'] for c in res['choices']]\n",
    "            success, v = get_next_word_value(res,  aug_feature_range[f])\n",
    "\n",
    "            if not success:\n",
    "                pass\n",
    "                # print(\n",
    "                #     f\"Couldn't find value for [{idx}] prompt: {prompt}, the next word is {v}\"\n",
    "                # )\n",
    "            else:\n",
    "                df.at[idx, f\"aug_{f}\"] = v\n",
    "\n",
    "    df[\"aug_temperature\"] = df[\"aug_temperature_c\"].apply(lambda c: (c*1.8)+32 if not c is None else None)\n",
    "    if report_format:\n",
    "        df.to_csv('./spreadsheets/gpt4_aug_report.csv')\n",
    "    else:\n",
    "        df.to_csv('./spreadsheets/gpt4_aug_text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [\"I'm sorry, but I cannot provide a numerical value for body temperature based on the given context.\",\n",
    "#  'There is no numerical value provided in the given context for body temperature in degrees Celsius.',\n",
    "#  'There is no information provided in the given context about body temperature in degrees Celsius.',\n",
    "#  \"I'm sorry, but I cannot provide a numerical value for body temperature based on the given context.\",\n",
    "#  'There is no numerical value provided in the given context to predict the body temperature in degrees Celsius.',\n",
    "#  'There is no numerical value provided in the given context for body temperature in degrees Celsius.',\n",
    "#  'There is no numerical value provided in the given context to predict the body temperature in degrees Celsius.',\n",
    "#  'Unfortunately, the given context does not provide any information about the body temperature in degrees Celsius.',\n",
    "#  'There is no numerical value provided in the given context to predict the body temperature in degrees Celsius.',\n",
    "#  'There is no numerical value provided in the given context for body temperature in degrees Celsius.',\n",
    "#  'There is no numerical value provided in the given context for body temperature in degrees Celsius.',\n",
    "#  'There is no numerical value provided in the given context for body temperature in degrees Celsius.',\n",
    "#  'There is no numerical value provided in the given context for body temperature in degrees Celsius.',\n",
    "#  \"I'm sorry, but I cannot provide a numerical value for body temperature based on the given context.\",\n",
    "#  'There is no numerical value provided in the given context, so I cannot predict the body temperature in degrees Celsius.',\n",
    "#  'There is no numerical value provided in the given context for body temperature in degrees Celsius.',\n",
    "#  'There is no numerical value provided in the given context.',\n",
    "#  'There is no numerical value provided in the given context, so I cannot predict the body temperature in degrees Celsius.',\n",
    "#  'There is no numerical value provided in the given context for body temperature in degrees Celsius.',\n",
    "#  \"I'm sorry, but I cannot provide a numerical value for body temperature based on the given context.\",\n",
    "#  'There is no numerical value provided in the given context for body temperature in degrees Celsius.',\n",
    "#  \"I'm sorry, but I cannot predict the body temperature in degrees Celsius based on the given context.\",\n",
    "#  \"I'm sorry, but I cannot provide a numerical value for body temperature based on the given context.\",\n",
    "#  \"I'm sorry, but I cannot provide a numerical value for body temperature based on the given context.\",\n",
    "#  'There is no numerical value provided in the given context to predict the body temperature in degrees Celsius.',\n",
    "#  'There is no numerical value provided in the given context for body temperature in degrees Celsius.',\n",
    "#  'Unfortunately, the provided context does not mention the body temperature in degrees Celsius.',\n",
    "#  \"I'm sorry, but I cannot provide a numerical value for body temperature based on the given context.\",\n",
    "#  \"I'm sorry, but I cannot provide a numerical value for body temperature based on the given context.\",\n",
    "#  'There is no numerical value provided in the given context for body temperature in degrees Celsius.',\n",
    "#  'There is no numerical value provided in the given context for body temperature in degrees Celsius.',\n",
    "#  '37.5',\n",
    "#  'There is no numerical value provided in the given context for body temperature in degrees Celsius.',\n",
    "#  \"I'm sorry, but I cannot provide a numerical value for body temperature based on the given context.\",\n",
    "#  'There is no numerical value provided in the given context to predict the body temperature in degrees Celsius.',\n",
    "#  \"I'm sorry, but I cannot provide a numerical value for body temperature based on the given context.\",\n",
    "#  \"I'm sorry, but I cannot provide a numerical value for body temperature based on the given context.\",\n",
    "#  'There is no numerical value provided in the given context for body temperature in degrees Celsius.',\n",
    "#  \"I'm sorry, but I cannot provide a numerical value for body temperature based on the given context.\",\n",
    "#  \"I'm sorry, but I cannot provide a numerical value for body temperature based on the given context.\",\n",
    "#  'There is no numerical value provided in the given context for body temperature in degrees Celsius.',\n",
    "#  \"I'm sorry, but I cannot provide a numerical value for body temperature based on the given context.\",\n",
    "#  'Unfortunately, the given context does not provide any information about body temperature in degrees Celsius.',\n",
    "#  'There is no numerical value provided in the given context, so it is not possible to predict a specific body temperature in degrees Celsius.',\n",
    "#  'There is no numerical value provided in the given context for body temperature in degrees Celsius.',\n",
    "#  'There is no numerical value provided in the given context for body temperature in degrees Celsius.',\n",
    "#  'There is no numerical value provided in the given context to predict the body temperature in degrees Celsius.',\n",
    "#  'There is no numerical value provided in the given context for body temperature.',\n",
    "#  \"I'm sorry, but I cannot provide a numerical value for body temperature based on the given context.\",\n",
    "#  \"I'm sorry, but I cannot provide a numerical value for body temperature based on the given context.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for rf in [\n",
    "#     True,\n",
    "#     False,\n",
    "# ]:\n",
    "#     report_format = rf\n",
    "#     df = pd.read_csv(\"./spreadsheets/reflacx_clinical.csv\")\n",
    "#     df[\"temperature_c\"] = df[\"temperature\"].apply(lambda f: (f - 32) * 5 / 9)\n",
    "#     df = aug_df(\n",
    "#         MIMIC_EYE_PATH,\n",
    "#         REFLACX_LESION_LABEL_COLS,\n",
    "#         features_to_aug,\n",
    "#         feature_to_name_map,\n",
    "#         df,\n",
    "#         generator,\n",
    "#         progress=[15],\n",
    "#         report_format=report_format,\n",
    "#     )\n",
    "#     df[\"aug_temperature\"] = df[\"aug_temperature_c\"].apply(lambda c: (c*1.8)+32 if not c is None else None)\n",
    "#     if report_format:\n",
    "#         df.to_csv(\"./spreadsheets/zephyr_aug_report.csv\")\n",
    "#     else:\n",
    "#         df.to_csv(\"./spreadsheets/zephyr_aug_text.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['temperature_c'] = df['temperature'].apply(lambda f :(f-32) * 5/9 )\n",
    "# df = aug_df(MIMIC_EYE_PATH, REFLACX_LESION_LABEL_COLS, features_to_aug, feature_to_name_map, df, generator, progress=[1, 5, 25, 50], report_format=report_format)\n",
    "# df[\"aug_temperature\"] = df[\"aug_temperature_c\"].apply(lambda c: (c*1.8)+32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"aug_temperature\"] = df[\"aug_temperature_c\"].apply(lambda c: (c*1.8)+32)\n",
    "# if report_format:\n",
    "#     df.to_csv('./spreadsheets/llama2_aug_report.csv')\n",
    "# else:\n",
    "#     df.to_csv('./spreadsheets/llama2_aug_text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # df = aug_df(MIMIC_EYE_PATH, REFLACX_LESION_LABEL_COLS, features_to_aug, feature_to_name_map, df, generator, progress=[1, 5, 25, 50], report_format=report_format)\n",
    "# aug_feature_range = {f: (df[f].min(), df[f].max()) for f in features_to_aug}\n",
    "\n",
    "# for f in features_to_aug:\n",
    "#     df[f\"aug_{f}\"] = None\n",
    "\n",
    "# for f in features_to_aug:\n",
    "#     print(f\"Resolving {f}\")\n",
    "#     # aug the instance one by one\n",
    "#     for idx, data in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "#         prompt = get_prompt_for_mask(\n",
    "#             MIMIC_EYE_PATH,\n",
    "#             data,\n",
    "#             REFLACX_LESION_LABEL_COLS,\n",
    "#             feature_to_name_map,\n",
    "#             f,\n",
    "#             report_format=report_format,\n",
    "#         )\n",
    "\n",
    "\n",
    "#         v = get_generated_value(\n",
    "#             mask_filler, prompt, aug_feature_range[f], top_k=100,\n",
    "#         )\n",
    "#         if v is None:\n",
    "#             print(\n",
    "#                 f\"Couldn't find value for [{idx}] prompt: {prompt}\"\n",
    "#             )\n",
    "\n",
    "\n",
    "#         df.at[idx, f\"aug_{f}\"] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"aug_temperature\"] = df[\"aug_temperature_c\"].apply(lambda c: (c*1.8)+32)\n",
    "# if report_format:\n",
    "#     df.to_csv('./spreadsheets/bcb_aug_report.csv')\n",
    "# else:\n",
    "#     df.to_csv('./spreadsheets/bcb_aug_text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
